{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "from scipy.stats import gmean, hmean\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from scipy.spatial.distance import cdist\n",
    "from transformers import RobertaTokenizer\n",
    "from transformers import RobertaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 100\n",
    "DEVICE = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/laida/anaconda3/envs/myenv/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at ./roberta_base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('./roberta_base')\n",
    "model = RobertaModel.from_pretrained(\"./roberta_base\").eval()\n",
    "model.to(DEVICE)\n",
    "\n",
    "def tokenize(text):\n",
    "    return tokenizer(text, truncation=True, max_length=512, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"roft_duplicates_removed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Get MLE for one text\n",
    "Parameters:\n",
    "        text  --- text\n",
    "Returns:\n",
    "    real number or NumPy.nan  --- Intrinsic dimension value of the text in the input data\n",
    "                                                    estimated by Maximum Likelihood Estimation method.'''\n",
    "\n",
    "def get_mle_single(text):\n",
    "    inputs = tokenizer(text.replace('\\n', ' '), truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outp = model(**inputs)\n",
    "    mx_points = inputs['input_ids'].shape[1] - 2\n",
    "        \n",
    "    # Computations for shorter texts are unstable and we want to avoid them\n",
    "    if mx_points < MINIMAL_STABLE_LENGTH:     \n",
    "        return 0\n",
    "            \n",
    "    return MLE().fit_transform(outp[0][0].numpy()[1:-1])\n",
    "\n",
    "'''\n",
    "Get MLE for all texts in df[key] Pandas DataSeries (MLE method)\n",
    "Parameters:\n",
    "        df  --- Pandas DataFrame\n",
    "        key --- Name of the column\n",
    "        is_list --- Check if the elements of the df[key] are lists (appears in some data)\n",
    "        \n",
    "Returns:\n",
    "    numpy.array of shape (number_of_texts, 1) --- Intrinsic dimension values for all texts in the input data\n",
    "                                                    estimated by Maximum Likelihood Estimation method.\n",
    "'''\n",
    "\n",
    "def get_mle(df, key='text', is_list=False):\n",
    "    dims = []\n",
    "    for s in df[key]:\n",
    "        if is_list:\n",
    "            text = s[0]\n",
    "        else:\n",
    "            text = s\n",
    "            \n",
    "        dims.append(get_mle_single(text))\n",
    "    return np.array(dims).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обработка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>annotator</th>\n",
       "      <th>group</th>\n",
       "      <th>dec_strat_value</th>\n",
       "      <th>predicted_boundary_index</th>\n",
       "      <th>true_boundary_index</th>\n",
       "      <th>points</th>\n",
       "      <th>reason</th>\n",
       "      <th>...</th>\n",
       "      <th>prompt_body</th>\n",
       "      <th>generation</th>\n",
       "      <th>gen_body</th>\n",
       "      <th>recipe_familiarity</th>\n",
       "      <th>news_familiarity</th>\n",
       "      <th>stories_familiarity</th>\n",
       "      <th>gen_familiarity</th>\n",
       "      <th>native_speaker</th>\n",
       "      <th>read_guide</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-08-31 17:11:39.095000+00:00</td>\n",
       "      <td>finetuned</td>\n",
       "      <td>Recipes</td>\n",
       "      <td>1666</td>\n",
       "      <td>A</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>['9123971792800820313']</td>\n",
       "      <td>...</td>\n",
       "      <td>HOW TO MAKE: Baby Shell Pasta Salad With Kalam...</td>\n",
       "      <td>22877</td>\n",
       "      <td>Meanwhile, combine all dressing ingredients in...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-09-06 21:54:48.912000+00:00</td>\n",
       "      <td>finetuned</td>\n",
       "      <td>Recipes</td>\n",
       "      <td>1666</td>\n",
       "      <td>A</td>\n",
       "      <td>0.4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>['irrelevant']</td>\n",
       "      <td>...</td>\n",
       "      <td>HOW TO MAKE: Nest Cookies\\nIngredients:\\n1 12 ...</td>\n",
       "      <td>26444</td>\n",
       "      <td>Photograph by fans blistering bens down!_SEP_F...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-09-06 21:55:07.069000+00:00</td>\n",
       "      <td>finetuned</td>\n",
       "      <td>Recipes</td>\n",
       "      <td>1666</td>\n",
       "      <td>A</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>['irrelevant']</td>\n",
       "      <td>...</td>\n",
       "      <td>HOW TO MAKE: Pink Lemonade Cupcakes\\nIngredien...</td>\n",
       "      <td>26089</td>\n",
       "      <td>Fill prepared pans two-thirds full._SEP_Bake f...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-09-06 21:58:44.944000+00:00</td>\n",
       "      <td>finetuned</td>\n",
       "      <td>Recipes</td>\n",
       "      <td>1666</td>\n",
       "      <td>A</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>['326860638652886185']</td>\n",
       "      <td>...</td>\n",
       "      <td>HOW TO MAKE: Beef Stroganaff\\nIngredients:\\n1 ...</td>\n",
       "      <td>25963</td>\n",
       "      <td>I have added some green peppers, red peppers, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-09-06 21:59:16.230000+00:00</td>\n",
       "      <td>finetuned</td>\n",
       "      <td>Recipes</td>\n",
       "      <td>1666</td>\n",
       "      <td>A</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>['repetition']</td>\n",
       "      <td>...</td>\n",
       "      <td>HOW TO MAKE: One-Pan Creamy Chicken and Veggie...</td>\n",
       "      <td>23225</td>\n",
       "      <td>Add frozen veggies and pasta._SEP_Pour in chic...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8938</th>\n",
       "      <td>2022-06-14 06:01:13.813000+00:00</td>\n",
       "      <td>gpt2-xl</td>\n",
       "      <td>Short Stories</td>\n",
       "      <td>15114</td>\n",
       "      <td>C</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>['generic']</td>\n",
       "      <td>...</td>\n",
       "      <td>Leraje, captain of thirty legions of demon war...</td>\n",
       "      <td>35197</td>\n",
       "      <td>But this time, there would be no standing arou...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8939</th>\n",
       "      <td>2022-06-14 06:16:31.704000+00:00</td>\n",
       "      <td>davinci</td>\n",
       "      <td>Short Stories</td>\n",
       "      <td>15114</td>\n",
       "      <td>C</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>['generic']</td>\n",
       "      <td>...</td>\n",
       "      <td>The sky shined bright red._SEP_The sun blazed ...</td>\n",
       "      <td>34934</td>\n",
       "      <td>\"My only true love You'll be._SEP_I have searc...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8940</th>\n",
       "      <td>2022-06-14 06:22:54.638000+00:00</td>\n",
       "      <td>gpt2-xl</td>\n",
       "      <td>Short Stories</td>\n",
       "      <td>15114</td>\n",
       "      <td>C</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>['irrelevant']</td>\n",
       "      <td>...</td>\n",
       "      <td>People think I'm either eternally ill or just ...</td>\n",
       "      <td>35060</td>\n",
       "      <td>and I didn't even have my glasses on._SEP_I'm ...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8941</th>\n",
       "      <td>2022-06-14 06:26:21.071000+00:00</td>\n",
       "      <td>davinci</td>\n",
       "      <td>Short Stories</td>\n",
       "      <td>15114</td>\n",
       "      <td>C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>['repetition']</td>\n",
       "      <td>...</td>\n",
       "      <td>The writer sat hunched over his desk, his quil...</td>\n",
       "      <td>34231</td>\n",
       "      <td>He felt... **important**._SEP_He stood up, and...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8942</th>\n",
       "      <td>2022-06-14 06:27:14.490000+00:00</td>\n",
       "      <td>davinci</td>\n",
       "      <td>Short Stories</td>\n",
       "      <td>15114</td>\n",
       "      <td>C</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>['generic']</td>\n",
       "      <td>...</td>\n",
       "      <td>Its been one day and sixteen minutes since Ast...</td>\n",
       "      <td>34065</td>\n",
       "      <td>\"I'm going to take a look around here,\" Stiles...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8943 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  date      model        dataset  annotator  \\\n",
       "0     2021-08-31 17:11:39.095000+00:00  finetuned        Recipes       1666   \n",
       "1     2021-09-06 21:54:48.912000+00:00  finetuned        Recipes       1666   \n",
       "2     2021-09-06 21:55:07.069000+00:00  finetuned        Recipes       1666   \n",
       "3     2021-09-06 21:58:44.944000+00:00  finetuned        Recipes       1666   \n",
       "4     2021-09-06 21:59:16.230000+00:00  finetuned        Recipes       1666   \n",
       "...                                ...        ...            ...        ...   \n",
       "8938  2022-06-14 06:01:13.813000+00:00    gpt2-xl  Short Stories      15114   \n",
       "8939  2022-06-14 06:16:31.704000+00:00    davinci  Short Stories      15114   \n",
       "8940  2022-06-14 06:22:54.638000+00:00    gpt2-xl  Short Stories      15114   \n",
       "8941  2022-06-14 06:26:21.071000+00:00    davinci  Short Stories      15114   \n",
       "8942  2022-06-14 06:27:14.490000+00:00    davinci  Short Stories      15114   \n",
       "\n",
       "     group  dec_strat_value  predicted_boundary_index  true_boundary_index  \\\n",
       "0        A              0.4                         0                    2   \n",
       "1        A              0.4                         8                    8   \n",
       "2        A              0.4                         0                    7   \n",
       "3        A              0.4                         1                    7   \n",
       "4        A              0.4                         1                    2   \n",
       "...    ...              ...                       ...                  ...   \n",
       "8938     C              0.4                         5                    6   \n",
       "8939     C              1.0                         2                    7   \n",
       "8940     C              0.4                         5                    4   \n",
       "8941     C              0.0                         5                    7   \n",
       "8942     C              0.4                         3                    2   \n",
       "\n",
       "      points                   reason  ...  \\\n",
       "0          0  ['9123971792800820313']  ...   \n",
       "1          5           ['irrelevant']  ...   \n",
       "2          0           ['irrelevant']  ...   \n",
       "3          0   ['326860638652886185']  ...   \n",
       "4          0           ['repetition']  ...   \n",
       "...      ...                      ...  ...   \n",
       "8938       0              ['generic']  ...   \n",
       "8939       0              ['generic']  ...   \n",
       "8940       4           ['irrelevant']  ...   \n",
       "8941       0           ['repetition']  ...   \n",
       "8942       4              ['generic']  ...   \n",
       "\n",
       "                                            prompt_body generation  \\\n",
       "0     HOW TO MAKE: Baby Shell Pasta Salad With Kalam...      22877   \n",
       "1     HOW TO MAKE: Nest Cookies\\nIngredients:\\n1 12 ...      26444   \n",
       "2     HOW TO MAKE: Pink Lemonade Cupcakes\\nIngredien...      26089   \n",
       "3     HOW TO MAKE: Beef Stroganaff\\nIngredients:\\n1 ...      25963   \n",
       "4     HOW TO MAKE: One-Pan Creamy Chicken and Veggie...      23225   \n",
       "...                                                 ...        ...   \n",
       "8938  Leraje, captain of thirty legions of demon war...      35197   \n",
       "8939  The sky shined bright red._SEP_The sun blazed ...      34934   \n",
       "8940  People think I'm either eternally ill or just ...      35060   \n",
       "8941  The writer sat hunched over his desk, his quil...      34231   \n",
       "8942  Its been one day and sixteen minutes since Ast...      34065   \n",
       "\n",
       "                                               gen_body recipe_familiarity  \\\n",
       "0     Meanwhile, combine all dressing ingredients in...                  2   \n",
       "1     Photograph by fans blistering bens down!_SEP_F...                  2   \n",
       "2     Fill prepared pans two-thirds full._SEP_Bake f...                  2   \n",
       "3     I have added some green peppers, red peppers, ...                  2   \n",
       "4     Add frozen veggies and pasta._SEP_Pour in chic...                  2   \n",
       "...                                                 ...                ...   \n",
       "8938  But this time, there would be no standing arou...                  2   \n",
       "8939  \"My only true love You'll be._SEP_I have searc...                  2   \n",
       "8940  and I didn't even have my glasses on._SEP_I'm ...                  2   \n",
       "8941  He felt... **important**._SEP_He stood up, and...                  2   \n",
       "8942  \"I'm going to take a look around here,\" Stiles...                  2   \n",
       "\n",
       "      news_familiarity  stories_familiarity  gen_familiarity  native_speaker  \\\n",
       "0                    3                    5                2             Yes   \n",
       "1                    3                    5                2             Yes   \n",
       "2                    3                    5                2             Yes   \n",
       "3                    3                    5                2             Yes   \n",
       "4                    3                    5                2             Yes   \n",
       "...                ...                  ...              ...             ...   \n",
       "8938                 4                    2                1              No   \n",
       "8939                 4                    2                1              No   \n",
       "8940                 4                    2                1              No   \n",
       "8941                 4                    2                1              No   \n",
       "8942                 4                    2                1              No   \n",
       "\n",
       "     read_guide label  \n",
       "0           NaN     2  \n",
       "1           NaN     8  \n",
       "2           NaN     7  \n",
       "3           NaN     7  \n",
       "4           NaN     2  \n",
       "...         ...   ...  \n",
       "8938        Yes     6  \n",
       "8939        Yes     7  \n",
       "8940        Yes     4  \n",
       "8941        Yes     7  \n",
       "8942        Yes     2  \n",
       "\n",
       "[8943 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2665 4257 1724\n"
     ]
    }
   ],
   "source": [
    "print(len(df[df[\"dataset\"] == \"Short Stories\"]),\n",
    "len(df[df[\"dataset\"] == \"Recipes\"]), \n",
    "len(df[df[\"dataset\"] == \"New York Times\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(input_string):\n",
    "    input_string_2 = re.sub(r\"\\n\" , \" \", input_string)\n",
    "    input_string_2 = re.sub(r\"[^A-Za-z0-9 !\\\"$%&\\'()\\*+,-./:;?@^_`~]\" , \"\", input_string_2)\n",
    "    input_string_2 = re.sub(r\"[ ]+\", \" \", input_string_2)\n",
    "    input_string_2 = input_string_2.strip()\n",
    "    input_string_2\n",
    "    return input_string_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"HOW TO MAKE: Baby Shell Pasta Salad With Kalamata Olives and Roasted Fennel Ingredients: 1 lb small shell pasta, uncooked 1 12 cups fennel bulbs, cut in half lengthwise 2 medium onions or 1 large onion, chopped 1/2 inch thick 3 tablespoons olive oil or 3 tablespoons vegetable oil 1 cup fresh plum tomato, diced (do nto use canned for this recipe) 34-1 cup kalamata olive (more if desired) 12 cup assorted fresh herb, finely chopped (any kind you desire, I like to include basil with the herbs) 3 -4 garlic cloves, with the peel on (leave whole) 13 cup balsamic vinegar 13 cup olive oil 2 tablespoons barbecue sauce (any flavor desired) 2 tablespoons lime juice 14 cup romano cheese, grated or shredded or 1/4 cup parmesan cheese, grated or shredded dried chili pepper flakes (any amount for sprinkling)._SEP_Cook the pasta until eldente (don't over cook); drain, and rinse with cold water; set aside._SEP_Heat the oven to 375 degrees._SEP_Meanwhile, combine all dressing ingredients in a blender or food processor and blend until smooth._SEP_When the fennel is cool enough to handle, chop into bite size pieces._SEP_Combine pasta, vegetables, olives, tomatoes, and dressing in a bowl; toss well._SEP_Season with dried chile flakes._SEP_Cover and refrigerate for at least 2 hours before serving._SEP_Serve cold._SEP_*Note* If you are using uncooked pasta shells or other type of pasta, cook according to package directions._SEP_Also, do not overcook as it will become mushy!_SEP_You can also add cooked shrimp to the salad after the dressing and cook just before adding the dressing, but be sure to reserve some of the extra time to let the dressing thicken up a bit._SEP_Also, the original recipe is very good for a couple of things._SEP_For those that I'm not eat this, when you get the right?. :)._SEP_You can also want to make it a lot more than you don't eat it just as a dinner party dish._SEP_You can make it as a main course._SEP_Just put it on the table, you can have leftovers\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_string(df[\"prompt_body\"][0]) + \"_SEP_\" + clean_string(df[\"gen_body\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return tokenizer(text, max_length=512, truncation = True)\n",
    "\n",
    "def get_example(i):\n",
    "    human_written = clean_string(df['prompt_body'][i].replace(\"_SEP_\", ' ')) + \" \"\n",
    "    try:\n",
    "        model_written = clean_string(df['gen_body'][i].replace(\"_SEP_\", ' '))\n",
    "    except:\n",
    "        model_written = \"\"\n",
    "    human_input_ids = tokenize(human_written).input_ids[:-1]\n",
    "    model_written_ids = tokenize(model_written).input_ids[1:]\n",
    "    input_ids = (human_input_ids + model_written_ids[:-1])[:511] + [model_written_ids[-1]]\n",
    "    input_ids = torch.tensor([input_ids])\n",
    "    tags = np.append(np.zeros(len(human_input_ids)),  np.ones(len(model_written_ids)))\n",
    "    return input_ids, tags\n",
    "\n",
    "def get_embeddings(input_ids):\n",
    "    #device = \"cuda:0\"\n",
    "    inputs = input_ids.to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        out = model(inputs)\n",
    "    embeddings = out.last_hidden_state.detach().cpu().numpy()[0][1:-1]\n",
    "    return embeddings\n",
    "\n",
    "def process_embeddings(embeddings, tags):\n",
    "    mles = []\n",
    "    mle_tags = []\n",
    "\n",
    "    center_point = 0\n",
    "\n",
    "    for i in range(embeddings.shape[0] - WINDOW_SIZE + 1):\n",
    "        sub_embedding = embeddings[i: i + WINDOW_SIZE]\n",
    "        mle = MLE().fit_transform(sub_embedding)\n",
    "        mles.append(mle)\n",
    "        mle_tags.append(int(tags[center_point+i]))\n",
    "\n",
    "    mle_tags = np.array(mle_tags)\n",
    "    mles = np.array(mles)\n",
    "\n",
    "    ids_human = np.argwhere(mle_tags == 0).squeeze()\n",
    "    ids_gen = np.argwhere(mle_tags == 1).squeeze()\n",
    "    return mles, ids_human, ids_gen\n",
    "\n",
    "def plot_result(i):\n",
    "    plt.figure(figsize=(6, 2))\n",
    "    input_ids, tags = get_example(i)\n",
    "    embeddings = get_embeddings(input_ids)\n",
    "    mles, ids_human, ids_gen = process_embeddings(embeddings, tags)\n",
    "\n",
    "    plt.plot(ids_human, mles[ids_human], label = 'human')\n",
    "    plt.plot(ids_gen, mles[ids_gen], label = 'gen')\n",
    "    plt.legend()\n",
    "    print(tokenizer.decode(input_ids[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def prim_tree(adj_matrix, power=1.0):\n",
    "    infty = np.max(adj_matrix) + 1.0\n",
    "    \n",
    "    dst = np.ones(adj_matrix.shape[0]) * infty\n",
    "    visited = np.zeros(adj_matrix.shape[0], dtype=bool)\n",
    "    ancestor = -np.ones(adj_matrix.shape[0], dtype=int)\n",
    "\n",
    "    v, s = 0, 0.0\n",
    "    for i in range(adj_matrix.shape[0] - 1):\n",
    "        visited[v] = 1\n",
    "        ancestor[dst > adj_matrix[v]] = v\n",
    "        dst = np.minimum(dst, adj_matrix[v])\n",
    "        dst[visited] = infty\n",
    "        \n",
    "        v = np.argmin(dst)\n",
    "        \n",
    "        s += adj_matrix[v][ancestor[v]] ** power\n",
    "    return s.item()\n",
    "\n",
    "def sample_W(W, nSamples, isRandom=True):\n",
    "    n = W.shape[0]\n",
    "    random_indices = np.random.choice(n, size=nSamples, replace=False)\n",
    "    return W[random_indices]\n",
    "\n",
    "def calculate_ph_dim(W, min_points=40, max_points=510, point_jump=20, alpha=1.0, restarts=3, resamples=7):\n",
    "    # Computations for shorter texts are unstable and we want to avoid them\n",
    "    if W.shape[0] < MINIMAL_STABLE_LENGTH: \n",
    "        return np.nan\n",
    "    \n",
    "    m_candidates = []\n",
    "    for i in range(restarts): \n",
    "        test_n = range(min_points, max_points, point_jump)\n",
    "        lengths = []\n",
    "\n",
    "        for n in test_n:\n",
    "            reruns = np.ones(resamples)\n",
    "            for i in range(resamples):\n",
    "                tmp = sample_W(W, n)\n",
    "                reruns[i] = prim_tree(cdist(tmp, tmp), power=alpha)\n",
    "            lengths.append(np.median(reruns))\n",
    "\n",
    "        lengths = np.array(lengths)\n",
    "        x = np.log(np.array(list(test_n)))\n",
    "        y = np.log(lengths)\n",
    "\n",
    "        N = len(x)\n",
    "        m_candidates.append((N * (x * y).sum() - x.sum() * y.sum()) / (N * (x ** 2).sum() - x.sum() ** 2))\n",
    "    m = np.mean(m_candidates)\n",
    "    return alpha / (1 - m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Get CLS-tokens for all texts in df[key] Pandas DataSeries (RoBERTa-CLS baseline)\n",
    "Parameters:\n",
    "        df  --- Pandas DataFrame\n",
    "        key --- Name of the column\n",
    "        is_list --- Check if the elements of the df[key] are lists (appears in some data)\n",
    "        \n",
    "Returns:\n",
    "    numpy.array of shape (number_of_texts, size_of_embedding=768)\n",
    "'''\n",
    "\n",
    "def get_cls(df, key='text', is_list=False):\n",
    "    dims = np.zeros((len(df[key]),768))\n",
    "    cnt = 0\n",
    "    for text in tqdm(df[key]):\n",
    "        if is_list:\n",
    "            s = text[0]\n",
    "        else:\n",
    "            s = text\n",
    "        inputs = tokenizer(s.replace('\\n', ' '), truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            outp = model(**inputs)\n",
    "        dims[cnt] = outp[0][0].numpy()[0]\n",
    "        cnt += 1\n",
    "    return dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Get PHD for one text\n",
    "Parameters:\n",
    "        text  --- text\n",
    "        alpha --- Parameter alpha for PHD computattion\n",
    "\n",
    "Returns:\n",
    "    real number or NumPy.nan  --- Intrinsic dimension value of the text in the input data\n",
    "                                                    estimated by Persistence Homology Dimension method.'''\n",
    "def get_phd_single(text, alpha=1.0):\n",
    "    inputs = tokenizer(text.replace('\\n', ' '), truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outp = model(**inputs)\n",
    "        \n",
    "    mx_points = inputs['input_ids'].shape[1] - 2        \n",
    "    mn_points = 40\n",
    "    step = ( mx_points - mn_points ) // 7\n",
    "        \n",
    "    return calculate_ph_dim(outp[0][0].numpy()[1:-1],  min_points=mn_points, max_points=mx_points, \\\n",
    "                                     point_jump=step, alpha=alpha)\n",
    "\n",
    "def process_text_phd_with_window(text, alpha=1.0):\n",
    "    inputs = tokenizer(text.replace('\\n', ' '), truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outp = model(**inputs)\n",
    "        \n",
    "    embeddings = outp.last_hidden_state.detach().cpu().numpy()[0][1:-1]\n",
    "        \n",
    "    phds = []\n",
    "\n",
    "    center_point = 0\n",
    "    \n",
    "    mx_points = inputs['input_ids'].shape[1] - 2        \n",
    "    mn_points = 40\n",
    "    step = ( mx_points - mn_points ) // 7\n",
    "    \n",
    "    for i in range(0, embeddings.shape[0] - WINDOW_SIZE + 1, 5):\n",
    "        sub_embedding = embeddings[i: i + WINDOW_SIZE]\n",
    "        phd = calculate_ph_dim(outp[0][0].numpy()[1:-1],  min_points=mn_points, max_points=mx_points, \\\n",
    "                               point_jump=step, alpha=alpha,\n",
    "                               restarts=3, resamples=1)\n",
    "        phds.append(phd)\n",
    "\n",
    "    phds = np.array(phds)\n",
    "\n",
    "    return phds\n",
    "\n",
    "'''\n",
    "Get PHD for all texts in df[key] Pandas DataSeries (PHD method)\n",
    "Parameters:\n",
    "        df  --- Pandas DataFrame\n",
    "        key --- Name of the column\n",
    "        is_list --- Check if the elements of the df[key] are lists (appears in some data)\n",
    "        \n",
    "        alpha --- Parameter alpha for PHD computattion\n",
    "\n",
    "Returns:\n",
    "    numpy.array of shape (number_of_texts, 1) --- Intrinsic dimension values for all texts in the input data\n",
    "                                                    estimated by Persistence Homology Dimension method.\n",
    "'''\n",
    "\n",
    "def get_phd(df, key='text', is_list=False, alpha=1.0):\n",
    "    dims = []\n",
    "    for s in tqdm(df[key]):\n",
    "        if is_list:\n",
    "            text = s[0]\n",
    "        else:\n",
    "            text = s\n",
    "        dims.append(get_phd_single(text, alpha=alpha))\n",
    "\n",
    "    return np.array(dims).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вычисление размерностей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                   | 3/8943 [02:16<113:04:13, 45.53s/it]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MINIMAL_STABLE_LENGTH = 60\n",
    "\n",
    "maxlim = len(df)\n",
    "dims_arr = []\n",
    "\n",
    "for i in tqdm(range(maxlim)):\n",
    "    human = (\" \".join(df['prompt_body'][i].split(\"_SEP_\")[:10])).strip()\n",
    "    human_written = clean_string(human.replace(\"_SEP_\", ' ')) + \" \"\n",
    "    try:\n",
    "        model_written = clean_string(df['gen_body'][i].replace(\"_SEP_\", ' '))\n",
    "    except:\n",
    "        model_written = \"\"\n",
    "    text = human_written + model_written\n",
    "    dims_arr.append(process_text_phd_with_window(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dims_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dims_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(list(map(len, dims_arr)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_df_from_lists(lists):\n",
    "    time_series_df = pd.DataFrame(columns=[\"id\", \"time\", \"dim\"])\n",
    "\n",
    "    for i in tqdm(range(len(lists))):\n",
    "        for j in range(len(lists[i])):\n",
    "            new_row = {\"id\": i, \"time\": j, \"dim\": lists[i][j]}\n",
    "            time_series_df = time_series_df.append(new_row, ignore_index=True)\n",
    "    return time_series_df\n",
    "\n",
    "    # ????? super-slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_dict_from_lists(lists):\n",
    "    time_series_dict = {\"id\": [], \"time\": [], \"dim\": []}\n",
    "\n",
    "    for i in tqdm(range(len(lists))):\n",
    "        try:\n",
    "            for j in range(len(lists[i])):\n",
    "                time_series_dict[\"id\"].append(i)\n",
    "                time_series_dict[\"time\"].append(j)\n",
    "                time_series_dict[\"dim\"].append(lists[i][j])\n",
    "        except:\n",
    "            time_series_dict[\"id\"].append(i)\n",
    "            time_series_dict[\"time\"].append(-1)\n",
    "            time_series_dict[\"dim\"].append(-1)\n",
    "    return time_series_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims_dict = time_series_dict_from_lists(dims_arr)\n",
    "dims_df = pd.DataFrame.from_dict(dims_dict)\n",
    "dims_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims_df.to_csv(\"sliding_window_data/roft_dublicates_removed_dims_timeseries_PHD_\" + str(WINDOW_SIZE) + \".csv\", \n",
    "               index=False\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_humans_dict = time_series_dict_from_lists(ids_humans)\n",
    "id_humans_df = pd.DataFrame.from_dict(id_humans_dict)\n",
    "id_humans_df.to_csv(\"sliding_window_data/chatgpt_roft_id_humans_timeseries_\" + str(WINDOW_SIZE) + \".csv\",\n",
    "                    index=False\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_humans_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
